{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e68ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "### Info for PyArrow Install https://www.delftstack.com/howto/python/read-and-write-parquet-files-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcac997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary.\n",
    "data = {}\n",
    "# Loop through the tables.\n",
    "for tableNumber in range(1, 6):\n",
    "    # Assign the path to a variable to use when accessing the file.\n",
    "    table_import_path = f'Resources/flight_data_{tableNumber}.parquet'\n",
    "    # Load the data frame.\n",
    "    df = pd.read_parquet(table_import_path)\n",
    "    # Make boolean data numeric.\n",
    "    df[\"isBasicEconomy\"] = df[\"isBasicEconomy\"].replace(\"True\", 1).replace(\"False\", 0)\n",
    "    df[\"isRefundable\"] = df[\"isRefundable\"].replace(\"True\", 1).replace(\"False\", 0)\n",
    "    df[\"isNonStop\"] = df[\"isNonStop\"].replace(\"True\", 1).replace(\"False\", 0)\n",
    "    # Make dates and 'travelDuration' object data into datetime\n",
    "    df['searchDate'] = pd.to_datetime(df['searchDate'])\n",
    "    df['flightDate'] = pd.to_datetime(df['flightDate'])\n",
    "    df['travelDuration'] = pd.to_timedelta(df['travelDuration'])\n",
    "    # Add new column for how many days before a flight a search took place.\n",
    "    df[\"searchDaysBeforeFlight\"] = pd.to_datetime(df[\"flightDate\"]) - pd.to_datetime(df[\"searchDate\"])\n",
    "    # Remove some columns.\n",
    "    df.drop(columns=['legId','fareBasisCode','elapsedDays','baseFare','seatsRemaining',\n",
    "                     'segmentsDepartureTimeEpochSeconds','segmentsDepartureTimeRaw',\n",
    "                     'segmentsArrivalTimeEpochSeconds','segmentsArrivalTimeRaw','segmentsArrivalAirportCode',\n",
    "                     'segmentsDepartureAirportCode','segmentsAirlineName','segmentsAirlineCode',\n",
    "                     'segmentsEquipmentDescription','segmentsDurationInSeconds',\n",
    "                     'segmentsDistance','segmentsCabinCode'], inplace=True, errors='ignore')\n",
    "    # Assign the path to a variable to use when accessing the file.\n",
    "    table_export_path = f'Resources/flight_data_clean_{tableNumber}.csv'\n",
    "    # Export table to csv.\n",
    "    df.to_csv(table_export_path)\n",
    "    # Copy the dataframe to the dictionary.\n",
    "    data[tableNumber] = df\n",
    "# Join the tables.\n",
    "df = pd.concat([data[1], data[2], data[3], data[4], data[5]], axis=0)\n",
    "# Recalculate the row numbers.\n",
    "df = df.reset_index()\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d157eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the path to a variable to use when accessing the file.\n",
    "table_export_path = f'Resources/flight_data_clean_all.csv'\n",
    "# Export table to csv.\n",
    "df.to_csv(table_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d3f2c",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "Essential data cleaning methods to consider when first interacting with a new dataset:\n",
    "\n",
    "**Check for missing values**: Check the dataset for any missing values and decide on a strategy to handle them, such as imputing the missing values or removing the affected rows/columns.\n",
    "\n",
    "**Check for duplicates**: Check the dataset for any duplicate records and decide on a strategy to handle them, such as removing the duplicates or aggregating them.\n",
    "\n",
    "**Check for data types**: Check the data types of each column in the dataset to ensure they are appropriate for the data they represent. For example, dates should be represented as dates and not as strings.\n",
    "\n",
    "**Check for outliers**: Check for any outliers or extreme values in the dataset that may skew your analysis, and decide on a strategy to handle them, such as removing them or replacing them with more appropriate values.\n",
    "\n",
    "**Check for inconsistencies**: Check for inconsistencies or errors in the data, such as typos or formatting issues, and decide on a strategy to handle them, such as cleaning the data or removing the affected records.\n",
    "\n",
    "**Normalize or scale the data**: If you have numerical data that varies widely in magnitude, consider normalizing or scaling the data so that the values are comparable.\n",
    "\n",
    "**Check for data quality**: Check the overall quality of the data, such as the accuracy and completeness of the information, to ensure that the data is suitable for analysis.\n",
    "\n",
    "(Thanks ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9604bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb28f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c857351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb58262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"{col} column: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb061e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e0e47e5",
   "metadata": {},
   "source": [
    "# Converting Duration Column to proper DateTime Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f974d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn travelDuration column into DateTime\n",
    "df['travelDuration'] = pd.to_timedelta(df['travelDuration'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ebc30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
